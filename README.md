# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #5 выполнил(а):
- Деньщик Дарья Дмитриевна
- РИ-210950
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы
Научиться интегрировать экономическую систему в проект Unity и обучать ML-Agent.

## Задание 1
### Измените параметры файла. yaml-агента и определить какие параметры икак влияют на обучение модели.
Ход работы:
- Установить все библиотеки и обучить ML-Agent
![image](https://user-images.githubusercontent.com/104368430/204712113-6413d3da-17f2-468a-a545-54710509eb94.png)
- Полуить графики:
![image](https://user-images.githubusercontent.com/104368430/204712945-3595cd9d-e5ec-4584-98b4-01feb7df6a76.png)
![image](https://user-images.githubusercontent.com/104368430/204712975-21436605-68e6-4e52-8e9f-a2bb402710da.png)
- После я изменила параметры файла. yaml-агента и выяснила, какие параметры и как влияют на обучение модели:

1) num_epochs - Количество проходов через буфер опыта во время градиентного спуска. Если не указано, то по умолчанию будет указано количество эпох, установленное для PPO. Уменьшение этого параметра обеспечит более стабильные обновления за счет более медленного обучения.

2) learnin_rate - Начальная скорость обучения для градиентного спуска. Обычно это значение следует уменьшить, если тренировка нестабильна, а вознаграждение не увеличивается последовательно.

3) epsilon - Соответствует допустимому порогу расхождения между старой и новой политиками обучения при обновлении с градиентным спуском. Установка этого значения небольшим приведет к более стабильным обновлениям, но также замедлит процесс обучения.

4) save_steps - Количество шагов тренажера между моментальными снимками (снапшотами) текущей политики обучения.

5) beta - Сила регуляризации энтропии. beta-значение должно быть скорректировано таким образом, чтобы энтропия (можно посмотреть в TensorBoard) медленно уменьшалась вместе с увеличением вознаграждения.

## Задание 2
### Построить графики зависимости количества эпох от ошибки обучения. Указать от чего зависит необходимое количество эпох обучения.

![image](https://user-images.githubusercontent.com/104368430/203941457-e88be278-4419-44c9-9bea-72a0e08299a2.png)
необходимое количество эпох обучения зависит от bias (смещение) и weights (вес) =>
```
double DotProductBias(double[] v1, double[] v2) 
	{
		if (v1 == null || v2 == null)
			return -1;
	 
		if (v1.Length != v2.Length)
			return -1;
	 
		double d = 0;
		for (int x = 0; x < v1.Length; x++)
		{
			d += v1[x] * v2[x];
		}

		d += bias;
	 
		return d;
	}

	double CalcOutput(int i)
	{
		double dp = DotProductBias(weights,ts[i].input);
		if(dp > 0) return(1);
		return (0);
	}
```

## Задание 3
### Построить визуальную модель работы перцептрона на сцене Unity. 
Ход работы: 
 - Создадим модель для работы фунции OR. Черные кубы - единицы, белые - нули. Результат работы = результат логического сложения.
  
![image](https://user-images.githubusercontent.com/104368430/203980095-88e12f5d-c187-4358-b992-dbcd3f1c6184.png)
 - Создадим скрипт для изменения цвета при столкновении.

```
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

public class ChangeColor : MonoBehaviour
{
    private void OnTriggerEnter(Collider other)
    {
        if (other.gameObject.GetComponent<Renderer>().material.color == Color.white && this.gameObject.GetComponent<Renderer>().material.color == Color.white)
        {
            other.gameObject.GetComponent<Renderer>().material.color = Color.white;
            this.gameObject.GetComponent<Renderer>().material.color = Color.white;
        }
        else
        {
            other.gameObject.GetComponent<Renderer>().material.color = Color.black;
            this.gameObject.GetComponent<Renderer>().material.color = Color.black;
        }
    }
}

```

 - При запуске программы видим, что все работает корректно (цвета кубов правильно меняются в зависимости от выполнения логического сложения)
  
![movie_001](https://user-images.githubusercontent.com/104368430/203983746-7860cde5-f3ca-4371-96ff-e3ca284eb3fa.gif)

## Выводы
В ходе работы я познакомилась с работой перцептрона. Реализовала перцептрон, который умеет производить вычисления для разных логических функций, построила графики зависимостей, а так же визуализировала работу перцептрона на сцене Unity
